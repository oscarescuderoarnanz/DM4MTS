{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy as sc\n",
    "\n",
    "import sklearn\n",
    "from sklearn import feature_selection, datasets, model_selection, preprocessing, decomposition, metrics\n",
    "from sklearn.model_selection import validation_curve, learning_curve, cross_validate, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from python_utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../Libraries_Paper/libraries/Osc_libraries')\n",
    "import utils\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load the data (obtained in Matlab - TCK)\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the data arrays meet kernel condition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.io as sio\n",
    "\n",
    "def normData (X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def normData_minmax (X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def is_pos_def(A):\n",
    "    M = np.matrix(A)\n",
    "    return np.all(np.linalg.eigvals(M+M.transpose()) > 0)\n",
    "\n",
    "def load_data(folders, i, norm):\n",
    "    X_train = sio.loadmat('../../Step1_TCK/data_generated_by_tck/' + folders[i] + '/Ktrtr')\n",
    "    X_test = sio.loadmat('../../Step1_TCK/data_generated_by_tck/' + folders[i] + '/Ktrte')\n",
    "    X_train = X_train['Ktrtr']\n",
    "    X_test = X_test['Ktrte']\n",
    "    X_test = X_test.T\n",
    "    \n",
    "    y_train = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Subconjuntos_3D/' + folders[i] + '/y_train_tensor.csv')\n",
    "    y_test = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Subconjuntos_3D/' + folders[i] + '/y_test_tensor.csv')\n",
    "\n",
    "    if norm:\n",
    "        X_train, X_test = normData (X_train, X_test)\n",
    "  \n",
    "    eigenvalues = np.linalg.eig(X_train)\n",
    "    matriz = np.array(X_train)\n",
    "    if (np.sum(np.abs(eigenvalues[0])>0) == X_train.shape[0]) and (np.array_equal(matriz, matriz.T)):\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Positive eigenvalue and symmetric matrix\")\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Meets kernel condition\")\n",
    "        print(\"---------------------------\")\n",
    "    else:\n",
    "        print(\"==============================\")\n",
    "        print(\"NO Meets kernel condition\")\n",
    "        print(\"==============================\")\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    return pd.DataFrame(X_train), pd.DataFrame(y_train), pd.DataFrame(X_test), pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "def matrixIsKernel(X_train, X_test):\n",
    "    print(\"Without normalizing the kernel. Data entered to TCK already normalized. \\n Out meets the kernel condition?: \")\n",
    "    print(is_pos_def(X_train))\n",
    "\n",
    "    print(\"Normalizing the kernel. Data entered to TCK already normalized. \\n Out meets the kernel condition?: \")\n",
    "    X_train, X_test = normData(X_train, X_test)\n",
    "    print(is_pos_def(X_train))\n",
    "    \n",
    "    print(\"Normalizing the kernel. Data entered to TCK already normalized. \\n Out meets the kernel condition?: \")\n",
    "    X_train, X_test = normData_minmax(X_train, X_test)\n",
    "    print(is_pos_def(X_train))\n",
    "\n",
    "    \n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.loc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def nuSVM(params, debug, folders, norm, random_state):\n",
    "\n",
    "    matrix_all_values = np.zeros((16, len(folders)))\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "        \n",
    "        print()\n",
    "        print(\"###################### RESULTS [SVM] FOLDER \" + folders[i] + \" ######################\")\n",
    "        print()\n",
    "        \n",
    "        X_pre_train, y_pre_train, X_test, y_test = load_data(folders, i, norm)\n",
    "\n",
    "        semillas = [9,18,35,52,75]\n",
    "\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=False)\n",
    "        kf.get_n_splits(X_pre_train)\n",
    "\n",
    "        bestHyperparameters = {'nu': 0}\n",
    "\n",
    "        bestMetricDev = 0\n",
    "        for c in range(len(params['nu'])):\n",
    "            clf = svm.NuSVC(kernel=\"precomputed\", nu=params['nu'][c], probability=True, random_state=random_state)\n",
    "\n",
    "            roc_auc_score = []\n",
    "            threshold_1 = []\n",
    "            threshold_2 = 0\n",
    "            y_pred_arr = []\n",
    "            # Divide the test set in k partitions\n",
    "            for train_index, val_index in kf.split(X_pre_train):\n",
    "\n",
    "                X_train, X_val = X_pre_train.iloc[train_index,train_index].reset_index(drop=True), X_pre_train.iloc[val_index,train_index].reset_index(drop=True)\n",
    "                y_train, y_val = y_pre_train.iloc[train_index].reset_index(drop=True), y_pre_train.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "                clf = clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "                threshold_1.append(Find_Optimal_Cutoff(y_val, y_pred))\n",
    "                auc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "                roc_auc_score.append(auc)\n",
    "\n",
    "                y_pred_arr.append(y_pred)\n",
    "\n",
    "\n",
    "            # Get the threshold for: model configured with hyperparameters with train data\n",
    "            y_pred_ttl = list(y_pred_arr[0])\n",
    "            y_pred_ttl.extend(y_pred_arr[1])\n",
    "            y_pred_ttl.extend(y_pred_arr[2])\n",
    "            y_pred_ttl.extend(y_pred_arr[3])\n",
    "            y_pred_ttl.extend(y_pred_arr[4])\n",
    "\n",
    "            threshold_2 = Find_Optimal_Cutoff(y_pre_train, y_pred_ttl)\n",
    "\n",
    "            if np.mean(roc_auc_score) > bestMetricDev:\n",
    "                bestMetricDev = np.mean(roc_auc_score)\n",
    "                bestHyperparameters['nu'] = params['nu'][c]\n",
    "                bestHyperparameters['threshold_1'] = np.mean(threshold_1)\n",
    "                bestHyperparameters['threshold_2'] = threshold_2\n",
    "                bestHyperparameters['y_pred_val'] = y_pred_ttl\n",
    "\n",
    "        if debug:\n",
    "            print(\"nu: \", bestHyperparameters[\"nu\"])\n",
    "            if (bestHyperparameters[\"nu\"] == np.min(params['nu'])) or (bestHyperparameters[\"nu\"] == np.max(params['nu'])):\n",
    "                print(\"==============================================================\")\n",
    "                print(\"WARNING!!!!!!!\")\n",
    "                print(\"==============================================================\")\n",
    "\n",
    "\n",
    "        clf = svm.NuSVC(kernel=\"precomputed\", nu=bestHyperparameters['nu'], probability=True, random_state=random_state)\n",
    "        clf = clf.fit(X_pre_train, y_pre_train)\n",
    "        y_pred_test = clf.predict_proba(X_test)[:,1]\n",
    "        y_pred_Xtrain = clf.predict(X_pre_train)\n",
    "        \n",
    "        selecCalculateMetrics_aux = ['umbral: 0.5' , \n",
    "                                     'umbral: threshold_2 (datos train)']\n",
    "                        \n",
    "            \n",
    "        for j in range(len(selecCalculateMetrics_aux)):\n",
    "            \n",
    "            v_accuracy_test = []\n",
    "            v_accuracy_train = []\n",
    "            v_specificity = []\n",
    "            v_sensitivity = []\n",
    "            v_precision = []\n",
    "            v_recall = []\n",
    "            v_f1score = []\n",
    "            v_accuracy = []\n",
    "            auc_score = []\n",
    "\n",
    "            if selecCalculateMetrics_aux[j] == 'umbral: 0.5':           \n",
    "                auc_score.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "                y_pred = (y_pred_test > 0.5).astype('int')\n",
    "            elif selecCalculateMetrics_aux[j] == 'umbral: threshold_2 (datos train)':\n",
    "                auc_score.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "                y_pred = (y_pred_test > bestHyperparameters[\"threshold_2\"]).astype('int')\n",
    "\n",
    "\n",
    "            v_specificity, v_recall, v_f1score, v_precision, v_accuracy, v_accuracy_test, v_accuracy_train = utils.calculateconfusionmatrix(y_pred, y_pre_train, y_test, v_specificity, v_recall, v_f1score, v_precision, v_accuracy, v_accuracy_test, v_accuracy_train, 0, y_pred_Xtrain)\n",
    "            \n",
    "            matrix_all_values[j*8:j*8 + 8, i] = v_specificity[0], v_recall[0], v_f1score[0], v_precision[0], v_accuracy[0], v_accuracy_test[0], v_accuracy_train[0], auc_score[0]\n",
    "                                 \n",
    "    \n",
    "    print()\n",
    "    print(\"###################### FINAL RESULTS  - With threshold train ######################\")\n",
    "    print()\n",
    "    \n",
    "    utils.printOutAlgorithm(matrix_all_values[8,:], matrix_all_values[9,:], matrix_all_values[10,:], matrix_all_values[11,:], matrix_all_values[12,:], matrix_all_values[13,:], matrix_all_values[14,:], matrix_all_values[15,:])\n",
    "    \n",
    "    return matrix_all_values\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def LR(params, debug, folders, norm, kfold=5):  \n",
    "    matrix_all_values = np.zeros((16, len(folders)))\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "        \n",
    "        print()\n",
    "        print(\"###################### RESULTS [LR] FOLDER \" + folders[i] + \" ######################\")\n",
    "        print()\n",
    "        \n",
    "        X_pre_train, y_pre_train, X_test, y_test = load_data(folders, i, norm)\n",
    "        \n",
    "        kf = KFold(n_splits=kfold, shuffle=False)\n",
    "        kf.get_n_splits(X_pre_train)\n",
    "\n",
    "        bestHyperparameters = {'C': 0}\n",
    "\n",
    "        bestMetricDev = 0\n",
    "        for c in range(len(params['C'])):\n",
    "\n",
    "            clf = LogisticRegression(solver='liblinear', C=params['C'][c], penalty='l1', n_jobs=32)\n",
    "\n",
    "            roc_auc_score = []\n",
    "            threshold_1 = []\n",
    "            threshold_2 = 0\n",
    "            y_pred_arr = []\n",
    "            # Divide the test set in k partitions\n",
    "            for train_index, val_index in kf.split(X_pre_train):\n",
    "                X_train, X_val = X_pre_train.iloc[train_index].reset_index(drop=True), X_pre_train.iloc[val_index].reset_index(drop=True)\n",
    "                y_train, y_val = y_pre_train.iloc[train_index].reset_index(drop=True), y_pre_train.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "\n",
    "                clf = clf.fit(np.array(X_train), np.array(y_train))\n",
    "                y_pred = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "                threshold_1.append(Find_Optimal_Cutoff(y_val, y_pred))\n",
    "                auc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "                roc_auc_score.append(auc)\n",
    "\n",
    "                y_pred_arr.append(y_pred)\n",
    "\n",
    "            # Get the threshold for: model configured with hyperparameters with train data\n",
    "            y_pred_ttl = list(y_pred_arr[0])\n",
    "            y_pred_ttl.extend(y_pred_arr[1])\n",
    "            y_pred_ttl.extend(y_pred_arr[2])\n",
    "            y_pred_ttl.extend(y_pred_arr[3])\n",
    "            y_pred_ttl.extend(y_pred_arr[4])\n",
    "\n",
    "            threshold_2 = Find_Optimal_Cutoff(y_pre_train, y_pred_ttl)\n",
    "\n",
    "            if np.mean(roc_auc_score) > bestMetricDev:\n",
    "                bestMetricDev = np.mean(roc_auc_score)\n",
    "                bestHyperparameters['C'] = params['C'][c]\n",
    "                bestHyperparameters['threshold_1'] = np.mean(threshold_1)\n",
    "                bestHyperparameters['threshold_2'] = threshold_2\n",
    "                bestHyperparameters['y_pred_val'] = y_pred_ttl\n",
    "\n",
    "        \n",
    "        print(\"Best roc auc score: \", bestMetricDev)\n",
    "        print(\"C: \", bestHyperparameters[\"C\"])\n",
    "        print(\"threshold obtained with train data: \", bestHyperparameters[\"threshold_2\"])\n",
    "        if (bestHyperparameters[\"C\"] == params['C'][0]) or (bestHyperparameters[\"C\"] == params['C'][-1]):\n",
    "            print(\"====================================================================================\")\n",
    "            print(\"Caution!\")\n",
    "            print(\"Value of C at lower or upper extrema\")\n",
    "            print(\"====================================================================================\")\n",
    "\n",
    "        clf = LogisticRegression(solver='liblinear', C=bestHyperparameters['C'],  penalty='l1', n_jobs=24)\n",
    "        clf = clf.fit(np.array(X_pre_train), np.array(y_pre_train))  \n",
    "        y_pred_test = clf.predict_proba(X_test)[:,1]\n",
    "        y_pred_Xtrain = clf.predict(X_pre_train)\n",
    "        \n",
    "        selecCalculateMetrics_aux = ['umbral: 0.5' , \n",
    "                                     'umbral: threshold_2 (datos train)']\n",
    "                        \n",
    "            \n",
    "        for j in range(len(selecCalculateMetrics_aux)):\n",
    "            \n",
    "            v_accuracy_test = []\n",
    "            v_accuracy_train = []\n",
    "            v_specificity = []\n",
    "            v_sensitivity = []\n",
    "            v_precision = []\n",
    "            v_recall = []\n",
    "            v_f1score = []\n",
    "            v_accuracy = []\n",
    "            auc_score = []\n",
    "\n",
    "            if selecCalculateMetrics_aux[j] == 'umbral: 0.5':\n",
    "                auc_score.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "                y_pred = (y_pred_test > 0.5).astype('int')\n",
    "            elif selecCalculateMetrics_aux[j] == 'umbral: threshold_2 (datos train)':\n",
    "                auc_score.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "                y_pred = (y_pred_test > bestHyperparameters[\"threshold_2\"]).astype('int')\n",
    "\n",
    "\n",
    "            v_specificity, v_recall, v_f1score, v_precision, v_accuracy, v_accuracy_test, v_accuracy_train = utils.calculateconfusionmatrix(y_pred, y_pre_train, y_test, v_specificity, v_recall, v_f1score, v_precision, v_accuracy, v_accuracy_test, v_accuracy_train, 0, y_pred_Xtrain)\n",
    "            \n",
    "            matrix_all_values[j*8:j*8 + 8, i] = v_specificity[0], v_recall[0], v_f1score[0], v_precision[0], v_accuracy[0], v_accuracy_test[0], v_accuracy_train[0], auc_score[0]\n",
    "                                 \n",
    "                \n",
    "    print()\n",
    "    print(\"###################### FINAL RESULTS  - With threshold train ######################\")\n",
    "    print()\n",
    "    \n",
    "    utils.printOutAlgorithm(matrix_all_values[8,:], matrix_all_values[9,:], matrix_all_values[10,:], matrix_all_values[11,:], matrix_all_values[12,:], matrix_all_values[13,:], matrix_all_values[14,:], matrix_all_values[15,:])\n",
    "    \n",
    "    return matrix_all_values\n",
    "    \n",
    "    \n",
    "        \n",
    "def randomForest(params, debug, folders, norm, kfold=5):  \n",
    "    matrix_all_values = np.zeros((16, len(folders)))\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "        \n",
    "        print()\n",
    "        print(\"###################### RESULTS [random forest] FOLDER \" + folders[i] + \" ######################\")\n",
    "        print()\n",
    "\n",
    "        X_pre_train, y_pre_train, X_test, y_test = load_data(folders, i, norm)\n",
    "\n",
    "        kf = KFold(n_splits=kfold, shuffle=False)\n",
    "        kf.get_n_splits(X_pre_train)\n",
    "\n",
    "        bestHyperparameters = {'min_samples_leaf': 0, 'max_depth':0, 'n_estimators':0}\n",
    "\n",
    "        bestMetricDev = 0\n",
    "        for msl in range(len(params['min_samples_leaf'])):\n",
    "            for md in range(len(params['max_depth'])):\n",
    "                for ne in range(len(params['n_estimators'])):\n",
    "                    clf = RandomForestClassifier(min_samples_leaf=params['min_samples_leaf'][msl], max_depth=params['max_depth'][md], n_estimators=params['n_estimators'][ne], n_jobs=24)\n",
    "\n",
    "                    roc_auc_score = []\n",
    "                    threshold_1 = []\n",
    "                    threshold_2 = 0\n",
    "                    y_pred_arr = []\n",
    "                    # Divide the test set in k partitions\n",
    "                    for train_index, val_index in kf.split(X_pre_train):\n",
    "                        X_train, X_val = X_pre_train.iloc[train_index].reset_index(drop=True), X_pre_train.iloc[val_index].reset_index(drop=True)\n",
    "                        y_train, y_val = y_pre_train.iloc[train_index].reset_index(drop=True), y_pre_train.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "\n",
    "                        clf = clf.fit(np.array(X_train), np.array(y_train))\n",
    "                        y_pred = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "                        threshold_1.append(Find_Optimal_Cutoff(y_val, y_pred))\n",
    "                        auc = sklearn.metrics.roc_auc_score(y_val, y_pred)\n",
    "                        roc_auc_score.append(auc)\n",
    "\n",
    "                        y_pred_arr.append(y_pred)\n",
    "\n",
    "\n",
    "                    y_pred_ttl = list(y_pred_arr[0])\n",
    "                    y_pred_ttl.extend(y_pred_arr[1])\n",
    "                    y_pred_ttl.extend(y_pred_arr[2])\n",
    "                    y_pred_ttl.extend(y_pred_arr[3])\n",
    "                    y_pred_ttl.extend(y_pred_arr[4])\n",
    "\n",
    "                    threshold_2 = Find_Optimal_Cutoff(y_pre_train, y_pred_ttl)\n",
    "\n",
    "                    if np.mean(roc_auc_score) > bestMetricDev:\n",
    "                        bestMetricDev = np.mean(roc_auc_score)\n",
    "                        bestHyperparameters['min_samples_leaf'] = params['min_samples_leaf'][msl]\n",
    "                        bestHyperparameters['max_depth'] = params['max_depth'][md]\n",
    "                        bestHyperparameters['n_estimators'] = params['n_estimators'][ne]\n",
    "                        bestHyperparameters['threshold_1'] = np.mean(threshold_1)\n",
    "                        bestHyperparameters['threshold_2'] = threshold_2\n",
    "                        bestHyperparameters['y_pred_val'] = y_pred_ttl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Best roc auc score: \", bestMetricDev)\n",
    "        print(\"min_samples_leaf: \", bestHyperparameters[\"min_samples_leaf\"])\n",
    "        print(\"max_depth: \", bestHyperparameters[\"max_depth\"])\n",
    "        print(\"n_estimators: \", bestHyperparameters[\"n_estimators\"])\n",
    "        print(\"threshold obtained with train data: \", bestHyperparameters[\"threshold_2\"])\n",
    "\n",
    "        if (bestHyperparameters[\"min_samples_leaf\"] == params['min_samples_leaf'][0]) or (bestHyperparameters[\"min_samples_leaf\"] == params['min_samples_leaf'][-1]):\n",
    "            print(\"====================================================================================\")\n",
    "            print(\"Caution!\")\n",
    "            print(\"Value of min_samples_leaf at low end or high extrema\")\n",
    "            print(\"====================================================================================\")\n",
    "        if (bestHyperparameters[\"max_depth\"] == params['max_depth'][0]) or (bestHyperparameters[\"max_depth\"] == params['max_depth'][-1]):\n",
    "            print(\"====================================================================================\")\n",
    "            print(\"Caution!\")\n",
    "            print(\"Value of max_depth at low end or high extrema\")\n",
    "            print(\"====================================================================================\")\n",
    "        if (bestHyperparameters[\"n_estimators\"] == params['n_estimators'][0]) or (bestHyperparameters[\"n_estimators\"] == params['n_estimators'][-1]):\n",
    "            print(\"====================================================================================\")\n",
    "            print(\"Caution!\")\n",
    "            print(\"Value of n_estimators at low end or high extrema\")\n",
    "            print(\"====================================================================================\")\n",
    "\n",
    "\n",
    "        clf = RandomForestClassifier(min_samples_leaf=bestHyperparameters['min_samples_leaf'], max_depth=bestHyperparameters['max_depth'], n_estimators=bestHyperparameters['n_estimators'], n_jobs=24)\n",
    "        clf = clf.fit(np.array(X_pre_train), np.array(y_pre_train))  \n",
    "        y_pred_test = clf.predict_proba(X_test)[:,1]\n",
    "        y_pred_Xtrain = clf.predict(X_pre_train)\n",
    "        \n",
    "\n",
    "        y_pred_Xtrain = clf.predict(X_pre_train)\n",
    "        \n",
    "        selecCalculateMetrics_aux = ['umbral: 0.5' , \n",
    "                                     'umbral: threshold_2 (datos train)']                        \n",
    "            \n",
    "        for j in range(len(selecCalculateMetrics_aux)):\n",
    "            \n",
    "            v_accuracy_test = []\n",
    "            v_accuracy_train = []\n",
    "            v_specificity = []\n",
    "            v_sensitivity = []\n",
    "            v_precision = []\n",
    "            v_recall = []\n",
    "            v_f1score = []\n",
    "            v_accuracy = []\n",
    "            auc_score = []\n",
    "\n",
    "            if selecCalculateMetrics_aux[j] == 'umbral: 0.5':\n",
    "                auc_score.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "                y_pred = (y_pred_test > 0.5).astype('int')\n",
    "            elif selecCalculateMetrics_aux[j] == 'umbral: threshold_2 (datos train)':\n",
    "                auc_score.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "                y_pred = (y_pred_test > bestHyperparameters[\"threshold_2\"]).astype('int')\n",
    "\n",
    "            v_specificity, v_recall, v_f1score, v_precision, v_accuracy, v_accuracy_test, v_accuracy_train = utils.calculateconfusionmatrix(y_pred, y_pre_train, y_test, v_specificity, v_recall, v_f1score, v_precision, v_accuracy, v_accuracy_test, v_accuracy_train, 0, y_pred_Xtrain)\n",
    "            \n",
    "            matrix_all_values[j*8:j*8 + 8, i] = v_specificity[0], v_recall[0], v_f1score[0], v_precision[0], v_accuracy[0], v_accuracy_test[0], v_accuracy_train[0], auc_score[0]\n",
    "                                 \n",
    "        \n",
    "    print()\n",
    "    print(\"###################### FINAL RESULTS RF ######################\")\n",
    "    print()\n",
    "    \n",
    "    print(\"====> WITH THRESHOLD OBTAINED WITH THE TRAIN DATA\")\n",
    "    print()\n",
    "    utils.printOutAlgorithm(matrix_all_values[8,:], matrix_all_values[9,:], matrix_all_values[10,:], matrix_all_values[11,:], matrix_all_values[12,:], matrix_all_values[13,:], matrix_all_values[14,:], matrix_all_values[15,:])\n",
    "\n",
    "       \n",
    "    return matrix_all_values\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS - LR, RF, SVM AND NU-SVM FOR KERNEL TCK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ttl_05 = {}\n",
    "results_ttl_train = {}\n",
    "\n",
    "folders = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = False\n",
    "C = [.0000001, .000001, .00001, .0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, .75, 1, 3, 5, 8, 10 ,12, 15]\n",
    "params = {'C': C}\n",
    "debug = True\n",
    "\n",
    "results_LR = LR(params, debug, folders, norm)\n",
    "results_ttl_05['LR'] = results_LR[[0,1,7], :]\n",
    "results_ttl_train['LR'] = results_LR[[8,9,15], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = False\n",
    "max_depth = np.arange(10, 42, 4)\n",
    "min_samples_leaf = np.array([2, 4, 9,  13,  17,  22,  43])\n",
    "n_estimators = np.array([30, 50, 100, 200, 400, 600])\n",
    "\n",
    "params = {'max_depth': max_depth,\n",
    "         'min_samples_leaf': min_samples_leaf,\n",
    "         'n_estimators': n_estimators}\n",
    "debug = True\n",
    "\n",
    "results_RF = randomForest(params, debug, folders, norm)\n",
    "results_ttl_05['RF'] = results_RF[[0,1,7], :]\n",
    "results_ttl_train['RF'] = results_RF[[8,9,15], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nu = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.75, 0.9]\n",
    "params = {'nu': nu}\n",
    "random_state = 30\n",
    "\n",
    "results_nuSVM = nuSVM(params, debug, folders, norm, random_state)\n",
    "results_ttl_05['nuSVM'] = results_nuSVM[[0,1,7], :]\n",
    "results_ttl_train['nuSVM'] = results_nuSVM[[8,9,15], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(results_ttl, name):\n",
    "    print(list(results_ttl.keys()))\n",
    "    values = list(results_ttl.values())\n",
    "    arr = []\n",
    "    for i in range(len(values)):\n",
    "        for j in range(len(values[i])):\n",
    "            arr.append(values[i][j])\n",
    "\n",
    "    df_results_ttl_AE = pd.DataFrame(arr)\n",
    "    print(df_results_ttl_AE.shape)\n",
    "    # rows: specificity, sensitivity and roc-auc\n",
    "    # columns: folders\n",
    "    df_results_ttl_AE.to_excel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(results_ttl_05, '../results_kernels/TCK/exponential_05.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(results_ttl_train, '../results_kernels/TCK/exponential_train.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
