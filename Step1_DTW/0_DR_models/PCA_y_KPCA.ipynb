{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy as sc\n",
    "\n",
    "import sklearn\n",
    "from sklearn import feature_selection, datasets, model_selection, preprocessing, decomposition, metrics\n",
    "from sklearn.model_selection import validation_curve, learning_curve, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../Libraries_Paper/libraries/Osc_libraries')\n",
    "import utils\n",
    "\n",
    "from python_utils import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn import manifold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMON FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTSNE(X,y):\n",
    "    red = y == 0\n",
    "    green = y == 1\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    tsne = manifold.TSNE(n_components=2, init='random', random_state=0, perplexity=30)\n",
    "    Y = tsne.fit_transform(X)\n",
    "    principalDf = pd.DataFrame(data = Y,\n",
    "                               columns = ['pca1', 'pca2'])\n",
    "    \n",
    "    class_0 = np.where(y == 0)\n",
    "    class_1 = np.where(y == 1)\n",
    "    \n",
    "    plt.scatter(Y[class_0, 0], Y[class_0, 1], marker='o', color='red')\n",
    "    plt.scatter(Y[class_1, 0], Y[class_1, 1], marker='x', color='green')\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"1st principal component\")\n",
    "    plt.ylabel(\"2nd principal component\")\n",
    "    plt.legend(['non-MDR', 'MDR'],prop={'size': 14})\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normData_minmax (X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def my_scorer(estimator, X, y=None):\n",
    "    X_reduced = estimator.transform(X)\n",
    "    X_preimage = estimator.inverse_transform(X_reduced)\n",
    "    return -1 * mean_squared_error(X, X_preimage)\n",
    "\n",
    "def plotKPCA(X, gamma, ncomp):\n",
    "    kpca = KernelPCA(n_components=ncomp, kernel='rbf', gamma=gamma)\n",
    "  \n",
    "    kpca_transform = kpca.fit_transform(X)\n",
    "    \n",
    "    autovalores = kpca.lambdas_\n",
    "    \n",
    "\n",
    "    explained_variance = np.var(kpca_transform, axis=0)\n",
    "    ev = explained_variance / np.sum(explained_variance)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.cumsum(ev))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return autovalores, kpca_transform\n",
    "\n",
    "def plotPCA(X_train, X_test, emplained_variance):\n",
    "    pca = PCA(n_components=emplained_variance)\n",
    "\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "        \n",
    "    ev = pca.explained_variance_ratio_\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.cumsum(ev))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return X_train_pca,X_test_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DTW = DTW_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = True\n",
    "folders = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]\n",
    "dependencia = \"DTW_D\"\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    print(folders[i])\n",
    "    print(\"Balanced data --> \" + dependencia)\n",
    "    X_train = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_train.csv')\n",
    "    X_test = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_test.csv')\n",
    "\n",
    "    y_train = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_train_tensor.csv')\n",
    "    y_test = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_test_tensor.csv')\n",
    "    \n",
    "\n",
    "    if norm:\n",
    "        X_train, X_test = normData_minmax (X_train, X_test)\n",
    "        \n",
    "    gamma = 1\n",
    "    X_train = np.exp(-gamma*X_train)\n",
    "    X_test = np.exp(-gamma*X_test)\n",
    "\n",
    "    emplained_variance = 0.99\n",
    "    data_train_PCA_1,data_test_PCA_1 = plotPCA(X_train, X_test, emplained_variance)\n",
    "\n",
    "    plotTSNE(data_train_PCA_1,y_train)\n",
    "    \n",
    "    pd.DataFrame(data_train_PCA_1).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/PCA/X_train_Norm_PCA_\" + folders[i] + \".csv\", index=False)\n",
    "    pd.DataFrame(data_test_PCA_1).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/PCA/X_test_Norm_PCA_\" + folders[i] + \".csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. DTW = DTW_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = True\n",
    "folders = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]\n",
    "dependencia = \"DTW_I\"\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    print(folders[i])\n",
    "    print(\"Balanced data --> \" + dependencia)\n",
    "    X_train = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_train.csv')\n",
    "    X_test = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_test.csv')\n",
    "\n",
    "    y_train = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_train_tensor.csv')\n",
    "    y_test = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_test_tensor.csv')\n",
    "    \n",
    "\n",
    "    if norm:\n",
    "        X_train, X_test = normData_minmax (X_train, X_test)\n",
    "        \n",
    "    gamma = 1\n",
    "    X_train = np.exp(-gamma*X_train)\n",
    "    X_test = np.exp(-gamma*X_test)\n",
    "\n",
    "    emplained_variance = 0.99\n",
    "    data_train_PCA_2,data_test_PCA_2 = plotPCA(X_train, X_test, emplained_variance)\n",
    "\n",
    "    plotTSNE(data_train_PCA_2,y_train)\n",
    "    \n",
    "    pd.DataFrame(data_train_PCA_2).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/PCA/X_train_Norm_PCA_\" + folders[i] + \".csv\", index=False)\n",
    "    pd.DataFrame(data_test_PCA_2).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/PCA/X_test_Norm_PCA_\" + folders[i] + \".csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def my_scorer(estimator, X, y=None):\n",
    "    X_reduced = estimator.fit_transform(X)\n",
    "    X_preimage = estimator.inverse_transform(X_reduced)\n",
    "    return -1 * mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTSNE(X,y):\n",
    "    red = y == 0\n",
    "    green = y == 1\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    tsne = manifold.TSNE(n_components=2, init='random', random_state=0, perplexity=30)\n",
    "    Y = tsne.fit_transform(X)\n",
    "    principalDf = pd.DataFrame(data = Y,\n",
    "                               columns = ['pca1', 'pca2'])\n",
    "\n",
    "    print(principalDf)\n",
    "    \n",
    "    class_0 = np.where(y == 0)\n",
    "    class_1 = np.where(y == 1)\n",
    "\n",
    "    plt.plot(Y[class_0, 0], Y[class_0, 1], \"ko\", color='red',mfc='none')\n",
    "    plt.plot(Y[class_1, 0], Y[class_1, 1], \"kx\", color='green')\n",
    "    \n",
    "    plt.scatter(Y[class_0, 0], Y[class_0, 1], marker='o', color='red')\n",
    "    plt.scatter(Y[class_1, 0], Y[class_1, 1], marker='x', color='green')\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel(\"1st principal component\")\n",
    "    plt.ylabel(\"2nd principal component\")\n",
    "    plt.legend(['non-MDR', 'MDR'],prop={'size': 14})\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return principalDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DTW = DTW_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "folders = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]\n",
    "\n",
    "semillas = [9,18,35, 52, 75]\n",
    "norm = True\n",
    "dependencia = \"DTW_D\"\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    print(folders[i])\n",
    "\n",
    "    X_train = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_train.csv')\n",
    "    X_test = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_test.csv')\n",
    "\n",
    "    y_train = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_train_tensor.csv')\n",
    "    y_test = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_test_tensor.csv')\n",
    "    \n",
    "    \n",
    "    param_grid = [{\n",
    "        \"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "        \"n_components\" : [20, 30, 35, 40, 45, 50, 60, 70],\n",
    "        \"alpha\": [.0005, .001] \n",
    "    }]\n",
    "\n",
    "    \n",
    "    if norm:\n",
    "        X_train_pre, X_test = normData_minmax (X_train, X_test)\n",
    "\n",
    "\n",
    "    kpca = KernelPCA(fit_inverse_transform=True, n_jobs=-1) \n",
    "    grid_search_1 = GridSearchCV(kpca, param_grid, cv=5, scoring=my_scorer)\n",
    "    grid_search_1.fit(X_train_pre)\n",
    "\n",
    "\n",
    "    print(\"========>\", grid_search_1.best_params_)\n",
    "    \n",
    "    kpca_aux_1 = KernelPCA(n_components=grid_search_1.best_params_['n_components'],\n",
    "                     kernel=grid_search_1.best_params_['kernel'],\n",
    "                     n_jobs=-1) \n",
    "    data_train_KPCA_1 = kpca_aux_1.fit_transform(X_train_pre)\n",
    "    data_test_KPCA_1 = kpca_aux_1.transform(X_test)\n",
    "    \n",
    "\n",
    "    plotTSNE(data_train_KPCA_1,y_train)\n",
    "    \n",
    "    pd.DataFrame(data_train_KPCA_1).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/KPCA/X_train_Norm_KPCA_\" + folders[i] + \".csv\", index=False)\n",
    "    pd.DataFrame(data_test_KPCA_1).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/KPCA/X_test_Norm_KPCA_\" + folders[i] + \".csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DTW = DTW_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "folders = [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"]\n",
    "\n",
    "semillas = [9,18,35, 52, 75]\n",
    "norm = True\n",
    "dependencia = \"DTW_I\"\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    print(\"-----------------------------------------------------------------------------------\")\n",
    "    print(folders[i])\n",
    "\n",
    "    X_train = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_train.csv')\n",
    "    X_test = pd.read_csv('../data_generated_by_dtw/' + dependencia + '/' + folders[i] + '/X_test.csv')\n",
    "\n",
    "    y_train = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_train_tensor.csv')\n",
    "    y_test = pd.read_csv('../../df_to_load/DataToPaperAndTFM_Mod1/Otras normalizaciones/Subconjuntos_3D_norm/' + folders[i] + '/y_test_tensor.csv')\n",
    "    \n",
    "    \n",
    "    param_grid = [{\n",
    "        \"kernel\": [\"rbf\", \"sigmoid\"],\n",
    "        \"n_components\" : [20, 30, 40, 50, 60, 70, 80, 90],\n",
    "        \"alpha\": [.0005, .001] \n",
    "    }]\n",
    "\n",
    "    \n",
    "    if norm:\n",
    "        X_train_pre, X_test = normData_minmax (X_train, X_test)\n",
    "\n",
    "\n",
    "    kpca = KernelPCA(fit_inverse_transform=True, n_jobs=-1) \n",
    "    grid_search_2 = GridSearchCV(kpca, param_grid, cv=5, scoring=my_scorer)\n",
    "    grid_search_2.fit(X_train_pre)\n",
    "\n",
    "\n",
    "    print(\"========>\", grid_search_2.best_params_)\n",
    "    \n",
    "    kpca_aux_2 = KernelPCA(n_components=grid_search_2.best_params_['n_components'],\n",
    "                     kernel=grid_search_2.best_params_['kernel'],\n",
    "                     n_jobs=-1) \n",
    "    \n",
    "    data_train_KPCA_2 = kpca_aux_2.fit_transform(X_train_pre)\n",
    "    data_test_KPCA_2 = kpca_aux_2.transform(X_test)\n",
    "    \n",
    "\n",
    "    plotTSNE(data_train_KPCA_2,y_train)\n",
    "    \n",
    "    pd.DataFrame(data_train_KPCA_2).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/KPCA/X_train_Norm_KPCA_\" + folders[i] + \".csv\", index=False)\n",
    "    pd.DataFrame(data_test_KPCA_2).to_csv(\"../1_Clasifications_models/data_reduced/\" + dependencia + \"/KPCA/X_test_Norm_KPCA_\" + folders[i] + \".csv\", index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
